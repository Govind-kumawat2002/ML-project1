{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "insurance_log\\29-01-25-11-24-32.log\n"
     ]
    }
   ],
   "source": [
    "import logging , os # create the log file in our projects\n",
    "from datetime import datetime \n",
    "dir_name = \"insurance_log\"\n",
    "# os.makedirs(dir_name,exist_ok=True)\n",
    "time_stamp =datetime.now().strftime(\"%d-%m-%y-%H-%M-%S\")\n",
    "file_name=time_stamp+\".log\"\n",
    "log_file_path = os.path.join(dir_name,file_name)\n",
    "print(log_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging , os # create the log file in our projects\n",
    "from datetime import datetime \n",
    "dir_name = \"insurance_log\"\n",
    "os.makedirs(dir_name,exist_ok=True)\n",
    "time_stamp =datetime.now().strftime(\"%d-%m-%y-%H-%M-%S\")\n",
    "file_name=time_stamp+\".log\"\n",
    "log_file_path = os.path.join(dir_name,file_name)\n",
    "# print(log_file_path)\n",
    "logging.basicConfig(filename=log_file_path,level=logging.DEBUG,format='%(asctime)s-%(levelname)s,%(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'ZeroDivisionError'> division by zero <traceback object at 0x000002C3F5673B00>\n",
      "8\n",
      "C:\\Users\\kumaw\\AppData\\Local\\Temp\\ipykernel_21320\\2155015079.py\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "try:\n",
    "    10/0\n",
    "\n",
    "except Exception as e:\n",
    "    rror_class,error_message,exe_tb=sys.exc_info()\n",
    "    print(rror_class,error_message,exe_tb)\n",
    "    print(exe_tb.tb_frame.f_lineno)\n",
    "    print(exe_tb.tb_frame.f_code.co_filename)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "class InsuranceException(Exception):\n",
    "    def __init__(self,error_message:Exception,error_detail:sys ):\n",
    "        super().__init__(error_message)\n",
    "        self.error_message = InsuranceException.error_message_detail(error_message,error_detail=error_detail)\n",
    "    @staticmethod\n",
    "    def error_message_detail(error:Exception,error_detail:sys)->str:\n",
    "        error_class,error_message,exe_tb = error_detail.exc_info()\n",
    "        line_number=exe_tb.tb_frame.f_lineno\n",
    "        file_name =exe_tb.tb_frame.f_code.co_filename\n",
    "        error_message=f\"filename {file_name},and line number {line_number},and error class {error_class}\"\n",
    "        return error_message\n",
    "    def __str__(self):\n",
    "        return InsuranceException.__name__.__str__()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InsuranceException\n"
     ]
    }
   ],
   "source": [
    "# print(IndentationError)\n",
    "import  sys\n",
    "try:\n",
    "    10/0\n",
    "except Exception as e :\n",
    "    obj=InsuranceException(e,sys)\n",
    "    print(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InsuranceException\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(obj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as ps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=ps.read_csv('insurance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "first_portion = df.loc[0:df.shape[0]//2]\n",
    "second_portion = df.loc[(df.shape[0]//2)+1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(670, 7)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_portion.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second_portion.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import mysql.connector\n",
    "\n",
    "# conn = mysql.connector.connect(\n",
    "#     host=\"13.60.30.189\",\n",
    "#     user=\"root\",\n",
    "#     password=\"Password123!\",\n",
    "#     database=\"jai\"\n",
    "# )\n",
    "\n",
    "# if conn.is_connected():\n",
    "#     print(\"Connected to MySQL\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from source_code.logger import logging\n",
    "# from source_code.exception import InsuranceException\n",
    "# import sys ,os \n",
    "# from source_code.entity import config_entity\n",
    "# from source_code.dbconfig import connect_to_mogodb\n",
    "# from source_code.utils import is_mongoconnected\n",
    "# from source_code.components.data_ingestion import DataIngestion\n",
    "\n",
    "# traning_pipeline_obj=config_entity.TraningPipelineconfig()\n",
    "\n",
    "# dataingestion_config_obj=config_entity.Datainegestincongif(trainig_pipeline_config=traning_pipeline_obj)\n",
    "\n",
    "# mongo_connections=connect_to_mogodb(mogodb_string=dataingestion_config_obj.mongodb_string)\n",
    "# is_mongoconnected(mongo_connections)\n",
    "# DataIngestion_obj=DataIngestion(dataingestion_config_obj)\n",
    "# loading_dataset_artifact_value=DataIngestion_obj.loading_dataset()\n",
    "\n",
    "# # print(loading_dataset_artifact_value.Dataset_file_path)\n",
    "# # print(loading_dataset_artifact_value.Test_file_path)\n",
    "# # print(loading_dataset_artifact_value.Train_file_path)\n",
    "# loading_dataset_artifact_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from source_code.dbconfig import connect_to_mogodb\n",
    "# from source_code.logger import logging\n",
    "# from source_code.exception import InsuranceException\n",
    "# import sys ,os \n",
    "# from source_code.entity import config_entity\n",
    "# from source_code.dbconfig import connect_to_mogodb\n",
    "# from source_code.utils import is_mongoconnected\n",
    "# from source_code.components.data_ingestion import DataIngestion\n",
    "\n",
    "# traning_pipeline_obj=config_entity.TraningPipelineconfig()\n",
    "\n",
    "# dataingestion_config_obj=config_entity.Datainegestincongif(trainig_pipeline_config=traning_pipeline_obj)\n",
    "\n",
    "# mongo_connections=connect_to_mogodb(mogodb_string=dataingestion_config_obj.mongodb_string)\n",
    "# # is_mongoconnected(mongo_connections)\n",
    "# # mongo_connections.find()\n",
    "# # mongo_connection_nane =mongo_connections[self.dataingestionconfig_obj.mongo_collection_name]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# mongo_connections=connect_to_mogodb(os.getenv('mogodb_string'))\n",
    "# col=mongo_connections['mlproject_database']['ml_collection']\n",
    "# df=pd.DataFrame(list(col.find()))\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['bmi'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# # Load the CSV file\n",
    "# input_file = 'E:\\ML-project1\\insurance.csv'  # Path to the large CSV file\n",
    "# df = pd.read_csv(input_file)\n",
    "\n",
    "# # Split the dataframe into 2 parts\n",
    "# df_split = np.array_split(df, 2)\n",
    "\n",
    "# # Save each split dataframe into a new CSV file\n",
    "# df_split[0].to_csv('split_part_1.csv', index=False)\n",
    "# df_split[1].to_csv('split_part_2.csv', index=False)\n",
    "\n",
    "# print('CSV file split into two parts: split_part_1.csv and split_part_2.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=pd.read_csv(\"E:\\ML-project1\\split_part_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "df=pd.read_csv(\"E:\\ML-project1\\split_part_2.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>female</td>\n",
       "      <td>29.81</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>6500.2359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>male</td>\n",
       "      <td>31.57</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4837.5823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>female</td>\n",
       "      <td>31.16</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northeast</td>\n",
       "      <td>3943.5954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>male</td>\n",
       "      <td>29.70</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4399.7310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>female</td>\n",
       "      <td>31.02</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>6185.3208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex    bmi  children smoker     region    charges\n",
       "0   40  female  29.81         1     no  southeast  6500.2359\n",
       "1   30    male  31.57         3     no  southeast  4837.5823\n",
       "2   29  female  31.16         0     no  northeast  3943.5954\n",
       "3   36    male  29.70         0     no  southeast  4399.7310\n",
       "4   41  female  31.02         0     no  southeast  6185.3208"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "\n",
    "# Function to insert CSV data into MySQL\n",
    "def insert_csv_to_mysql(csv_file, host, user, password, database, table_name):\n",
    "    try:\n",
    "        # Read CSV data into a Pandas DataFrame\n",
    "        df = pd.read_csv(csv_file)\n",
    "\n",
    "        # Connect to the MySQL database\n",
    "        connection = mysql.connector.connect(\n",
    "             host=\"13.60.30.189\",\n",
    "            user=\"Admin\",\n",
    "            password=\"Password123!\",\n",
    "            database=\"jai\"\n",
    ")\n",
    "        \n",
    "\n",
    "        if connection.is_connected():\n",
    "            print(f\"Connected to MySQL database {database}\")\n",
    "\n",
    "            # Create a cursor object\n",
    "            cursor = connection.cursor()\n",
    "\n",
    "            # Iterate over the DataFrame and insert data into MySQL\n",
    "            for index, row in df.iterrows():\n",
    "                # Create an INSERT query\n",
    "                insert_query = f\"INSERT INTO {table_name} ({', '.join(df.columns)}) VALUES ({', '.join(['%s'] * len(df.columns))})\"\n",
    "                \n",
    "                # Insert the row data into the table\n",
    "                cursor.execute(insert_query, tuple(row))\n",
    "                \n",
    "            # Commit the transaction\n",
    "            connection.commit()\n",
    "            print(f\"Successfully inserted {len(df)} rows into {table_name}.\")\n",
    "\n",
    "    except Error as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    finally:\n",
    "        # Close the cursor and connection\n",
    "        if connection.is_connected():\n",
    "            cursor.close()\n",
    "            connection.close()\n",
    "            print(\"MySQL connection is closed.\")\n",
    "\n",
    "# Define your CSV file and MySQL details\n",
    "csv_file = 'E:\\ML-project1\\split_part_1.csv'  # Path to your CSV file\n",
    "host=\"13.60.30.189\",\n",
    "user=\"Admin\",\n",
    "password=\"Password123!\",\n",
    "database=\"jai\"\n",
    "table_name = 'mlproject'\n",
    "\n",
    "\n",
    "# Call the function to insert CSV data to MySQL\n",
    "insert_csv_to_mysql(csv_file, host, user, password, database, table_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from source_code.dbconfig import connect_to_mogodb,connect_to_mysql\n",
    "\n",
    "\n",
    "sql_connection=connect_to_mysql(host='16.171.3.98',user=\"Admin\",password='Password123!',database='room')\n",
    "logging.info(\"connect with mysql \")\n",
    "\n",
    "cursor =sql_connection.cursor()\n",
    "cursor.execute(\"SELECT * FROM insurance_data\")\n",
    "rows = cursor.fetchall()\n",
    "for row in rows:\n",
    "        print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "helfndsfkjf\n"
     ]
    }
   ],
   "source": [
    "print(\"helfndsfkjf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np \n",
    "import sys\n",
    "import pandas as pd \n",
    "from source_code.logger import logging\n",
    "from source_code.exception import InsuranceException\n",
    "# load dataset from dir \n",
    "from source_code.entity import config_entity,artifact_entity\n",
    "class Datacleaning:\n",
    "    def __init__(self,):\n",
    "    # def data_cleaning():\n",
    "            dataset_file_path=artifact_entity.Dataingenstionartifact.Dataset_file_path \n",
    "            total_train_file_path=artifact_entity.Dataingenstionartifact.total_Train_file_path\n",
    "            total_test_file_path=artifact_entity.Dataingenstionartifact.total_Test_file_path\n",
    "            total_df=pd.read_csv(total_train_file_path)\n",
    "            total_df.drop_duplicates(inplace=True)\n",
    "            size_of_the_data = total_df.shape\n",
    "            logging.info(f'shape of the data {size_of_the_data}')   \n",
    "            # to handle the missing value\n",
    "            logging.info('replacing na value with np.nan')\n",
    "            total_df.replace(to_replace='na',value=np.NAN,inplace=True)\n",
    "            logging.info('replaced')    \n",
    "            # to handle the null value \n",
    "            logging.info(\"remove the null  value from the dataset \")\n",
    "            total_df.dropna(inplace=True) \n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "      \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np \n",
    "import sys\n",
    "import pandas as pd \n",
    "from source_code.logger import logging\n",
    "from source_code.exception import InsuranceException\n",
    "# load dataset from dir \n",
    "from source_code.entity import config_entity,artifact_entity\n",
    "class Datacleaning:\n",
    "    def __init__(self,total_dataset_file_path:artifact_entity.Dataingenstionartifact,\n",
    "                 total_train_file_path:artifact_entity.Dataingenstionartifact,\n",
    "                  total_test_file_path:artifact_entity.Dataingenstionartifact ):\n",
    "            try:\n",
    "                  self.total_dataset_file_path=total_dataset_file_path\n",
    "                  self.total_train_file_path = total_train_file_path\n",
    "                  self.total_test_file_path= total_test_file_path\n",
    "                  pass\n",
    "            except Exception as e:\n",
    "                  raise InsuranceException(e ,sys)\n",
    "            \n",
    "    def data_cleaning(self):\n",
    "            \"\"\"\n",
    "            this funtion is used for data cleaning and manipulation of data\"\"\"\n",
    "\n",
    "            total_df=pd.read_csv(self.total_train_file_path)\n",
    "            total_df.drop_duplicates(inplace=True)\n",
    "            size_of_the_data = total_df.shape\n",
    "            logging.info(f'shape of the data {size_of_the_data}')   \n",
    "            # to handle the missing value\n",
    "            logging.info('replacing na value with np.nan')\n",
    "            total_df.replace(to_replace='na',value=np.NAN,inplace=True)\n",
    "            logging.info('replaced')    \n",
    "            # to handle the null value \n",
    "            logging.info(\"remove the null  value from the dataset \")\n",
    "            total_df.dropna(inplace=True)   \n",
    "            print(total_df)\n",
    "            \n",
    "\n",
    "\n",
    "      \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'Dataingenstionartifact' has no attribute 'Dataset_file_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m=\u001b[39mDatacleaning(total_dataset_file_path\u001b[38;5;241m=\u001b[39m\u001b[43martifact_entity\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataingenstionartifact\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataset_file_path\u001b[49m,total_test_file_path\u001b[38;5;241m=\u001b[39martifact_entity\u001b[38;5;241m.\u001b[39mDataingenstionartifact\u001b[38;5;241m.\u001b[39mtotal_Test_file_path,total_train_file_path\u001b[38;5;241m=\u001b[39martifact_entity\u001b[38;5;241m.\u001b[39mDataingenstionartifact\u001b[38;5;241m.\u001b[39mtotal_Train_file_path)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39mdata_cleaning()\n",
      "\u001b[1;31mAttributeError\u001b[0m: type object 'Dataingenstionartifact' has no attribute 'Dataset_file_path'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"insurance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Invalid data found:\n",
      "   age sex   bmi  children smoker     region    charges\n",
      "0   19   f  27.9         0    yes  southwest  16884.924\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define validation functions\n",
    "def validate_sex(value):\n",
    "    return value in [\"male\", \"female\"]\n",
    "\n",
    "def validate_bmi(value):\n",
    "    return isinstance(value, (int, float)) and value > 0\n",
    "\n",
    "def validate_children(value):\n",
    "    return isinstance(value, int) and value >= 0\n",
    "\n",
    "def validate_smoker(value):\n",
    "    return value in [\"yes\", \"no\"]\n",
    "\n",
    "def validate_region(value):\n",
    "    return value in [\"southeast\", \"southwest\", \"northeast\", \"northwest\"]\n",
    "\n",
    "def validate_charges(value):\n",
    "    return isinstance(value, (int, float)) and value >= 0\n",
    "\n",
    "# Apply validation checks\n",
    "invalid_rows = df[\n",
    "    (~df[\"sex\"].apply(validate_sex)) |\n",
    "    (~df[\"bmi\"].apply(validate_bmi)) |\n",
    "    (~df[\"children\"].apply(validate_children)) |\n",
    "    (~df[\"smoker\"].apply(validate_smoker)) |\n",
    "    (~df[\"region\"].apply(validate_region)) |\n",
    "    (~df[\"charges\"].apply(validate_charges))\n",
    "]\n",
    "\n",
    "# Display validation results\n",
    "if invalid_rows.empty:\n",
    "    print(\"✅ Data is valid!\")\n",
    "else:\n",
    "    print(\"⚠️ Invalid data found:\")\n",
    "    print(invalid_rows)\n",
    "    df.drop(invalid_rows.index,inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[0,'sex'] ='f'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>31</td>\n",
       "      <td>female</td>\n",
       "      <td>25.740</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>3756.62160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex     bmi  children smoker     region      charges\n",
       "1   18    male  33.770         1     no  southeast   1725.55230\n",
       "2   28    male  33.000         3     no  southeast   4449.46200\n",
       "3   33    male  22.705         0     no  northwest  21984.47061\n",
       "4   32    male  28.880         0     no  northwest   3866.85520\n",
       "5   31  female  25.740         0     no  southeast   3756.62160"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
